
import streamlit as st
import pandas as pd
import numpy as np
from mlxtend.frequent_patterns import apriori, association_rules
from sklearn.preprocessing import MultiLabelBinarizer
import re
from collections import Counter
import random

# --------------------------
# Config & Header
# --------------------------
st.set_page_config(page_title="Apriori ‚Äì Treino & Predi√ß√£o", layout="wide")
st.title("üõí Apriori com Duas Bases: Treino/Teste e Predi√ß√£o")

st.markdown('''
Voc√™ √© um **consultor de IA** ajudando um **mercado de bairro** a entender padr√µes de compra para **ofertas**, **layout da loja** e **estoque**.

**Fluxo da atividade**  
1) Carregue **duas bases** (ou gere sint√©ticas):  
   - **Treino/Teste (1000 transa√ß√µes)** ‚Üí aprender padr√µes e **gerar regras**.  
   - **Predi√ß√£o (100 transa√ß√µes)** ‚Üí **aplicar as regras** para **recomendar itens por carrinho**.  
2) Ajuste os **par√¢metros** do Apriori e dos filtros de regras.  
3) Avalie **cobertura** e **qualidade** das recomenda√ß√µes** e proponha a√ß√µes ao lojista.
''')

# --------------------------
# Gerador de bases sint√©ticas
# --------------------------
def gerar_transacoes_sinteticas(n, seed=42):
    random.seed(seed)
    np.random.seed(seed)

    lacteos = ["leite", "queijo", "manteiga", "iogurte"]
    panificados = ["p√£o", "biscoito", "bolo"]
    cafe_e_afins = ["caf√©", "a√ß√∫car", "filtro de caf√©"]
    massas = ["macarr√£o", "molho de tomate", "queijo ralado"]
    basicos = ["arroz", "feij√£o", "√≥leo", "farinha", "sal"]
    frios = ["presunto", "mussarela"]
    limpeza = ["detergente", "esponja", "sab√£o em p√≥", "amaciante"]
    higiene = ["papel higi√™nico", "sabonete", "creme dental", "escova de dente"]
    bebidas = ["refrigerante", "suco", "√°gua mineral"]
    snacks = ["batata chips", "chocolate", "bala"]

    base_pop = (
        lacteos + panificados + cafe_e_afins + massas + basicos +
        frios + limpeza + higiene + bebidas + snacks
    )

    transacoes = []
    for _ in range(n):
        cesta = set()
        tam = np.random.choice([2, 3, 4, 5, 6], p=[0.15, 0.30, 0.30, 0.18, 0.07])

        # Padr√µes (correla√ß√µes) para tornar Apriori significativo
        if random.random() < 0.35:
            cesta.add("leite")
            if random.random() < 0.60: cesta.add("p√£o")
            if random.random() < 0.40: cesta.add("manteiga")
        if random.random() < 0.30:
            cesta.add("caf√©")
            if random.random() < 0.70: cesta.add("a√ß√∫car")
            if random.random() < 0.35: cesta.add("filtro de caf√©")
        if random.random() < 0.28:
            cesta.add("macarr√£o")
            if random.random() < 0.70: cesta.add("molho de tomate")
            if random.random() < 0.50: cesta.add("queijo ralado")
        if random.random() < 0.40:
            cesta.add("arroz")
            if random.random() < 0.75: cesta.add("feij√£o")
            if random.random() < 0.45: cesta.add("√≥leo")
        if random.random() < 0.25:
            cesta.add("detergente")
            if random.random() < 0.5: cesta.add("esponja")
        if random.random() < 0.25:
            cesta.add("papel higi√™nico")
            if random.random() < 0.4: cesta.add("sabonete")

        # Completa a cesta at√© o tamanho alvo
        while len(cesta) < tam:
            cesta.add(random.choice(base_pop))

        transacoes.append(", ".join(sorted(cesta)))

    return pd.DataFrame({"Transacao": transacoes})

# --------------------------
# Helpers
# --------------------------
def split_itens(x: str):
    if pd.isna(x):
        return []
    partes = re.split(r"[;,]", str(x))
    return [p.strip().lower() for p in partes if p and p.strip()]

def listas_para_ohe(series_listas):
    mlb = MultiLabelBinarizer(sparse_output=False)
    ohe = mlb.fit_transform(series_listas)
    df_bin = pd.DataFrame(ohe, columns=mlb.classes_).astype(bool)
    return df_bin, mlb

def fs_to_text(fs):
    return ", ".join(sorted(list(fs)))

def carregar_csv(arquivo):
    # tenta ler com v√≠rgula; se falhar, usa ponto e v√≠rgula
    try:
        df = pd.read_csv(arquivo)
    except Exception:
        arquivo.seek(0)
        df = pd.read_csv(arquivo, sep=";")
    return df

def preparar_ohe(df, col_transacoes):
    listas = df[col_transacoes].apply(split_itens)
    df_bin, mlb = listas_para_ohe(listas)
    return df_bin, mlb, listas

# Aplica√ß√£o das regras em um carrinho
def aplicar_regras_em_cesta(itens_cesta_set, regras_df, top_k=None):
    recs = []
    for _, r in regras_df.iterrows():
        ante = r["antecedents"]
        cons = r["consequents"]
        if ante.issubset(itens_cesta_set):
            sugeridos = [c for c in cons if c not in itens_cesta_set]
            if sugeridos:
                recs.append((tuple(sorted(sugeridos)), r["lift"], r["confidence"], r["support"]))
    recs.sort(key=lambda x: (x[1], x[2], x[3]), reverse=True)
    if top_k:
        recs = recs[:top_k]
    return recs

# --------------------------
# Gera√ß√£o/Download de exemplos
# --------------------------
col_a, col_b, col_c = st.columns(3)
with col_a:
    if st.button("üß™ Gerar base **Treino/Teste** (1000)"):
        df_tt = gerar_transacoes_sinteticas(1000, seed=42)
        st.download_button("üì• Baixar Treino/Teste (1000)", df_tt.to_csv(index=False).encode("utf-8"),
                           "treino_1000.csv", "text/csv")
with col_b:
    if st.button("üß™ Gerar base **Predi√ß√£o** (100)"):
        df_pr = gerar_transacoes_sinteticas(100, seed=777)
        st.download_button("üì• Baixar Predi√ß√£o (100)", df_pr.to_csv(index=False).encode("utf-8"),
                           "predicao_100.csv", "text/csv")
with col_c:
    st.info("Use os bot√µes para baixar exemplos. Depois fa√ßa o upload das suas bases.")

# --------------------------
# Upload das bases
# --------------------------
st.markdown("### Upload das Bases")
col1, col2 = st.columns(2)
with col1:
    up_tt = st.file_uploader("üîº Base **Treino/Teste** (CSV, ‚â• 1000 linhas)", type=["csv"], key="tt")
with col2:
    up_pr = st.file_uploader("üîº Base **Predi√ß√£o** (CSV, ‚â• 100 linhas)", type=["csv"], key="pr")

# --------------------------
# Par√¢metros
# --------------------------
st.sidebar.header("Par√¢metros do Apriori e Regras")
min_sup = st.sidebar.slider("Suporte m√≠nimo (%)", 1, 50, 8,
                            help="Percentual m√≠nimo de cestas em que o itemset ocorre.") / 100
max_len = st.sidebar.slider("Tamanho m√°ximo do itemset", 1, 5, 3)
min_conf = st.sidebar.slider("Confian√ßa m√≠nima (%)", 10, 100, 50) / 100
min_lift = st.sidebar.number_input("Lift m√≠nimo", value=1.0, step=0.1)
min_ante = st.sidebar.slider("Tamanho m√≠nimo do antecedente", 1, 4, 1)
min_cons = st.sidebar.slider("Tamanho m√≠nimo do consequente", 1, 3, 1)
top_k_sug = st.sidebar.slider("Top-N recomenda√ß√µes por transa√ß√£o", 1, 10, 5)
produto_foco = st.sidebar.text_input("Filtrar por produto de interesse (opcional)", value="")

# --------------------------
# Processamento principal
# --------------------------
if up_tt and up_pr:
    # Leitura
    df_tt_raw = carregar_csv(up_tt)
    df_pr_raw = carregar_csv(up_pr)

    # Sele√ß√£o de colunas
    st.write("#### Selecione as colunas de transa√ß√µes")
    c1, c2 = st.columns(2)
    with c1:
        col_tt = st.selectbox(
            "Coluna da base Treino/Teste",
            options=list(df_tt_raw.columns),
            index=list(df_tt_raw.columns).index("Transacao") if "Transacao" in df_tt_raw.columns else 0,
            key="col_tt"
        )
    with c2:
        col_pr = st.selectbox(
            "Coluna da base Predi√ß√£o",
            options=list(df_pr_raw.columns),
            index=list(df_pr_raw.columns).index("Transacao") if "Transacao" in df_pr_raw.columns else 0,
            key="col_pr"
        )

    # Valida√ß√µes de tamanho
    n_tt = len(df_tt_raw)
    n_pr = len(df_pr_raw)

    ok_tt = (n_tt >= 1000)
    ok_pr = (n_pr >= 100)

    if not ok_tt:
        st.error(f"A base de **Treino/Teste** deve ter **pelo menos 1000** transa√ß√µes (recebidas: {n_tt}).")
    if not ok_pr:
        st.error(f"A base de **Predi√ß√£o** deve ter **pelo menos 100** transa√ß√µes (recebidas: {n_pr}).")

    if ok_tt and ok_pr:
        # One-hot
        df_tt_bin, mlb_tt, listas_tt = preparar_ohe(df_tt_raw, col_tt)
        df_pr_bin, mlb_pr, listas_pr = preparar_ohe(df_pr_raw, col_pr)

        st.markdown("### Amostra das transa√ß√µes processadas")
        ca, cb = st.columns(2)
        with ca:
            st.caption("Treino/Teste ‚Äî one-hot (5 primeiras)")
            st.dataframe(df_tt_bin.head())
        with cb:
            st.caption("Predi√ß√£o ‚Äî one-hot (5 primeiras)")
            st.dataframe(df_pr_bin.head())

        # Apriori na base de treino/teste
        freq_itens = apriori(df_tt_bin, min_support=min_sup, use_colnames=True, max_len=max_len)
        if freq_itens.empty:
            st.warning("Nenhum item frequente encontrado na base de Treino/Teste. Ajuste os par√¢metros.")
            st.stop()

        n_trans_tt = len(df_tt_bin)
        freq_itens["support_count"] = (freq_itens["support"] * n_trans_tt).round(0).astype(int)

        st.subheader("Itens frequentes (Treino/Teste)")
        st.dataframe(freq_itens.sort_values(["support", "itemsets"], ascending=[False, True]).reset_index(drop=True))

        # Regras
        regras = association_rules(freq_itens, metric="confidence", min_threshold=min_conf)
        if regras.empty:
            st.warning("Nenhuma regra foi gerada. Tente reduzir confian√ßa, aumentar max_len ou reduzir suporte.")
            st.stop()

        # Filtros de regras
        regras = regras[regras["lift"] >= min_lift].copy()
        regras["ante_len"] = regras["antecedents"].apply(lambda s: len(s))
        regras["cons_len"] = regras["consequents"].apply(lambda s: len(s))
        regras = regras[(regras["ante_len"] >= min_ante) & (regras["cons_len"] >= min_cons)]

        # Convers√£o amig√°vel
        regras["antecedents_txt"] = regras["antecedents"].apply(fs_to_text)
        regras["consequents_txt"] = regras["consequents"].apply(fs_to_text)

        # Filtro por produto de interesse (opcional)
        if produto_foco.strip():
            import re as _re
            p = _re.escape(produto_foco.strip().lower())
            regras = regras[
                regras["antecedents_txt"].str.contains(fr"\b{p}\b") |
                regras["consequents_txt"].str.contains(fr"\b{p}\b")
            ]

        if regras.empty:
            st.warning("Regras geradas, mas todas foram filtradas. Afrouxe os filtros ou limpe o 'produto de interesse'.")
            st.stop()

        ordem = st.selectbox("Ordenar regras por", options=["lift", "confidence", "support"], index=0)
        regras = regras.sort_values(by=ordem, ascending=False)

        cols_show = ["antecedents_txt", "consequents_txt", "support", "confidence", "lift", "leverage", "conviction"]
        st.subheader("Regras de associa√ß√£o (Treino/Teste)")
        st.dataframe(regras[cols_show].reset_index(drop=True), use_container_width=True)

        st.download_button(
            "‚¨áÔ∏è Baixar regras (CSV)",
            data=regras[cols_show].to_csv(index=False).encode("utf-8"),
            file_name="regras_apriori_treino.csv",
            mime="text/csv"
        )

        # --------------------------
        # Aplica√ß√£o das Regras na Base de Predi√ß√£o
        # --------------------------
        st.markdown("---")
        st.subheader("Aplica√ß√£o das Regras na Base de Predi√ß√£o")

        listas_pr_sets = [set(lst) for lst in listas_pr]
        regras_sorted = regras.sort_values(["lift", "confidence", "support"], ascending=False).copy()

        recs_por_transacao = []
        for idx, itens in enumerate(listas_pr_sets):
            recs = []
            for _, r in regras_sorted.iterrows():
                ante = r["antecedents"]
                cons = r["consequents"]
                if ante.issubset(itens):
                    sugeridos = [c for c in cons if c not in itens]
                    if sugeridos:
                        recs.append((tuple(sorted(sugeridos)), r["lift"], r["confidence"], r["support"]))
            # Ordena e aplica top-k
            recs.sort(key=lambda x: (x[1], x[2], x[3]), reverse=True)
            recs = recs[:top_k_sug]
            for sug, lift, conf, sup in recs:
                recs_por_transacao.append({
                    "id_transacao": idx,
                    "itens_existentes": ", ".join(sorted(itens)),
                    "recomendacao": ", ".join(sug),
                    "lift_regra": round(lift, 4),
                    "conf_regra": round(conf, 4),
                    "support_regra": round(sup, 4)
                })

        if recs_por_transacao:
            df_recs = pd.DataFrame(recs_por_transacao)

            st.write("#### Amostra das recomenda√ß√µes por transa√ß√£o (Predi√ß√£o)")
            st.dataframe(df_recs.head(20), use_container_width=True)

            # M√©tricas de cobertura e resumo
            transacoes_com_rec = df_recs["id_transacao"].nunique()
            total_pred = len(listas_pr_sets)
            cobertura = transacoes_com_rec / total_pred if total_pred else 0.0
            media_rec_por_trans = df_recs.groupby("id_transacao").size().mean()

            st.markdown(
                f'''
**Cobertura**: {transacoes_com_rec}/{total_pred} transa√ß√µes ({cobertura:.0%}) receberam ao menos 1 recomenda√ß√£o.  
**M√©dia de recomenda√ß√µes por transa√ß√£o (com recomenda√ß√£o)**: {media_rec_por_trans:.2f}
'''
            )

            # Top itens recomendados
            cont_recs = Counter()
            for r in recs_por_transacao:
                for it in [i.strip() for i in r["recomendacao"].split(",")]:
                    if it:
                        cont_recs[it] += 1
            top_itens = pd.DataFrame(cont_recs.most_common(10), columns=["item", "ocorrencias"])
            st.write("#### Top 10 itens mais recomendados")
            st.dataframe(top_itens, use_container_width=True)

            # Download das recomenda√ß√µes
            st.download_button(
                "‚¨áÔ∏è Baixar recomenda√ß√µes por transa√ß√£o (CSV)",
                data=df_recs.to_csv(index=False).encode("utf-8"),
                file_name="recomendacoes_predicao.csv",
                mime="text/csv"
            )
        else:
            st.info("Nenhuma transa√ß√£o da base de Predi√ß√£o recebeu recomenda√ß√£o com os filtros atuais. Afrouxe os par√¢metros.")

else:
    st.info("Envie **duas bases** (Treino/Teste e Predi√ß√£o) ou gere as sint√©ticas acima para come√ßar.")

# --------------------------
# Atividade (roteiro did√°tico)
# --------------------------
st.markdown('''
---
## üéØ Atividade proposta (vers√£o aprimorada)

1) **Prepare os dados**  
   - Use as bases sint√©ticas (1000 e 100) ou fa√ßa **upload** das suas.  
   - Garanta listas de itens na coluna de transa√ß√µes (ex.: `"leite, p√£o, manteiga"`).

2) **Aprenda as regras** na base **Treino/Teste**  
   - Varie **Suporte**, **Confian√ßa**, **Lift**, **Tamanho** de conjuntos.  
   - Registre **quantas regras** obteve e **quais s√£o as top 5 por *lift***.

3) **Aplique as regras** na base **Predi√ß√£o**  
   - Observe **Cobertura** (% de carrinhos com recomenda√ß√£o) e **M√©dia de recomenda√ß√µes por transa√ß√£o**.  
   - Liste os **Top 10 itens recomendados**.

4) **Recomenda√ß√µes ao neg√≥cio**  
   - Escolha **ao menos 2 regras** e explique como us√°‚Äëlas (combos, cross‚Äësell, layout de g√¥ndolas, precifica√ß√£o, *endcaps*).  
   - Proponha **um experimento A/B** simples para validar o impacto de uma recomenda√ß√£o no faturamento.

5) **Reflex√µes (responder no relat√≥rio)**  
   - Como **suporte** impacta a **escalabilidade operacional**?  
   - Como **confian√ßa** e **lift** impactam a **qualidade** das recomenda√ß√µes?  
   - Qual trade‚Äëoff voc√™ encontrou entre **n√∫mero de regras** e **relev√¢ncia**?  
   - Se um item √© muito popular, como isso influencia o **lift**?

> **Dica**: Foque em regras com **lift > 1** e **confian√ßa** alta; por√©m, um **suporte** muito baixo pode dificultar a execu√ß√£o pr√°tica na loja.
''')
