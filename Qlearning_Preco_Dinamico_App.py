
import streamlit as st
import numpy as np
import pandas as pd

st.title("üí∞ Pre√ßo Din√¢mico com Q-Learning (Simula√ß√£o)")

st.markdown("""
## üìå Contexto
Voc√™ √© um **consultor de IA** contratado por um e-commerce para maximizar o lucro atrav√©s de pre√ßos din√¢micos.  
Seu desafio: Treinar um agente Q-Learning que aprenda a escolher o melhor pre√ßo em diferentes cen√°rios de demanda.
""")

# Par√¢metros
states = ["Alta Demanda", "M√©dia Demanda", "Baixa Demanda"]
actions = ["Pre√ßo Baixo", "Pre√ßo M√©dio", "Pre√ßo Alto"]
n_states = len(states)
n_actions = len(actions)

# Q-Table
Q = np.zeros((n_states, n_actions))

# Par√¢metros do aluno
alpha = st.slider("Taxa de aprendizado (Œ±)", 0.01, 1.0, 0.1)
gamma = st.slider("Fator de desconto (Œ≥)", 0.01, 1.0, 0.9)
epsilon = st.slider("Taxa de explora√ß√£o (Œµ)", 0.0, 1.0, 0.2)
episodios = st.slider("N√∫mero de epis√≥dios de treino", 100, 5000, 1000)

# Fun√ß√£o de recompensa
def obter_recompensa(state, action):
    tabela_recompensa = {
        (0, 0): 8, (0, 1): 10, (0, 2): 12,  # Alta demanda
        (1, 0): 5, (1, 1): 8, (1, 2): 6,   # M√©dia demanda
        (2, 0): 3, (2, 1): 4, (2, 2): 2    # Baixa demanda
    }
    return tabela_recompensa[(state, action)]

# Treino
for _ in range(episodios):
    state = np.random.randint(0, n_states)
    if np.random.rand() < epsilon:
        action = np.random.randint(0, n_actions)
    else:
        action = np.argmax(Q[state])

    reward = obter_recompensa(state, action)
    next_state = np.random.randint(0, n_states)

    Q[state, action] += alpha * (reward + gamma * np.max(Q[next_state]) - Q[state, action])

# Mostrar Q-Table
df_q = pd.DataFrame(Q, index=states, columns=actions)
st.subheader("Q-Table final ap√≥s o treino")
st.dataframe(df_q.style.format("{:.2f}"))

st.markdown("""
## üéØ Atividade
‚úÖ Analise a pol√≠tica aprendida (Q-Table).  
‚úÖ Explique qual pre√ßo o agente recomenda para cada n√≠vel de demanda e por qu√™.  
‚úÖ Sugira como o e-commerce poderia usar isso no mundo real.
""")
